{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rbkn99/.local/lib/python3.6/site-packages/tensorflow/python/util/tf_inspect.py:75: DeprecationWarning:\n",
      "\n",
      "inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import graph_objs as go\n",
    "from scipy.stats import pearsonr\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from fbprophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import timedelta\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Flatten, Dropout, Activation\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "handler = logging.FileHandler('nn.log')\n",
    "handler.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "%matplotlib inline\n",
    "init_notebook_mode(connected = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPPredictor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    \n",
    "    def prepare_data(self, data, actual_date):\n",
    "        df = data.copy()\n",
    "        df.index = pd.to_datetime(df['Date'])\n",
    "        df.drop(['Date'], axis=1, inplace=True)\n",
    "        for col in df.columns:\n",
    "            df[col].interpolate(method='time', inplace=True)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        return df[df.index <= pd.to_datetime(actual_date)]\n",
    "\n",
    "    def fit(self, prepared_data, use_text_model=False):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(LSTM(\n",
    "            input_dim=1,\n",
    "            output_dim=50,\n",
    "            return_sequences=True))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(LSTM(\n",
    "            100,\n",
    "            return_sequences=False))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        model.add(Dense(\n",
    "            output_dim=1))\n",
    "        model.add(Activation('linear'))\n",
    "\n",
    "        model.compile(loss='mse', optimizer='rmsprop')\n",
    "        \n",
    "        df = pd.DataFrame({'ds': prepared_data.index, 'y': prepared_data['PPSpotAvgPrice']}).reset_index().drop(['Date'], axis=1)\n",
    "        df['ds'] = pd.to_numeric(df['ds'])\n",
    "        \n",
    "        self.scaler_X = MinMaxScaler()\n",
    "        X_train = np.reshape(np.array(df['ds']), (-1, 1))\n",
    "        X_train = self.scaler_X.fit_transform(X_train)\n",
    "        \n",
    "        self.scaler_y = MinMaxScaler()\n",
    "        y_train = np.reshape(np.array(df['y']), (-1, 1))\n",
    "        y_train = self.scaler_y.fit_transform(y_train)\n",
    "        \n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], 1, 1))\n",
    "        #y_train = np.reshape(y_train, (y_train.shape[0], 1, 1))\n",
    "        model.fit(X_train, y_train, batch_size=128, nb_epoch=10, validation_split=0.05)\n",
    "        \n",
    "        self.model = model\n",
    "        return model\n",
    "\n",
    "    \n",
    "    def predict(self, date):\n",
    "        X_test = np.array(pd.to_numeric(pd.Series(pd.to_datetime(date))))\n",
    "        X_test = np.reshape(X_test, (-1, 1))\n",
    "        X_test = self.scaler_X.transform(X_test)\n",
    "        X_test = np.reshape(X_test, (1, 1, 1))\n",
    "        forecast = self.model.predict(X_test)\n",
    "        return self.scaler_y.inverse_transform(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 201 samples, validate on 11 samples\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 4s 19ms/step - loss: 0.2669 - val_loss: 0.1867\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 0s 81us/step - loss: 0.2442 - val_loss: 0.1616\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 0s 87us/step - loss: 0.2272 - val_loss: 0.1396\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 0s 77us/step - loss: 0.2120 - val_loss: 0.1188\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 0s 99us/step - loss: 0.1979 - val_loss: 0.0992\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 0s 57us/step - loss: 0.1843 - val_loss: 0.0802\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 0s 92us/step - loss: 0.1717 - val_loss: 0.0635\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 0s 59us/step - loss: 0.1608 - val_loss: 0.0487\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 0s 89us/step - loss: 0.1494 - val_loss: 0.0353\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 0s 71us/step - loss: 0.1391 - val_loss: 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:MAPE for 2017-12-31: 8.12%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 206 samples, validate on 11 samples\n",
      "Epoch 1/10\n",
      "206/206 [==============================] - 4s 18ms/step - loss: 0.2637 - val_loss: 0.2089\n",
      "Epoch 2/10\n",
      "206/206 [==============================] - 0s 66us/step - loss: 0.2385 - val_loss: 0.1795\n",
      "Epoch 3/10\n",
      "206/206 [==============================] - 0s 47us/step - loss: 0.2198 - val_loss: 0.1532\n",
      "Epoch 4/10\n",
      "206/206 [==============================] - 0s 83us/step - loss: 0.2035 - val_loss: 0.1288\n",
      "Epoch 5/10\n",
      "206/206 [==============================] - 0s 81us/step - loss: 0.1882 - val_loss: 0.1060\n",
      "Epoch 6/10\n",
      "206/206 [==============================] - 0s 96us/step - loss: 0.1738 - val_loss: 0.0848\n",
      "Epoch 7/10\n",
      "206/206 [==============================] - 0s 89us/step - loss: 0.1600 - val_loss: 0.0656\n",
      "Epoch 8/10\n",
      "206/206 [==============================] - 0s 176us/step - loss: 0.1488 - val_loss: 0.0499\n",
      "Epoch 9/10\n",
      "206/206 [==============================] - 0s 117us/step - loss: 0.1380 - val_loss: 0.0356\n",
      "Epoch 10/10\n",
      "206/206 [==============================] - 0s 87us/step - loss: 0.1281 - val_loss: 0.0241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:MAPE for 2018-01-31: 9.34%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 209 samples, validate on 12 samples\n",
      "Epoch 1/10\n",
      "209/209 [==============================] - 4s 20ms/step - loss: 0.2636 - val_loss: 0.2204\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - 0s 49us/step - loss: 0.2393 - val_loss: 0.1907\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - 0s 56us/step - loss: 0.2212 - val_loss: 0.1639\n",
      "Epoch 4/10\n",
      "209/209 [==============================] - 0s 61us/step - loss: 0.2048 - val_loss: 0.1389\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - 0s 77us/step - loss: 0.1893 - val_loss: 0.1155\n",
      "Epoch 6/10\n",
      "209/209 [==============================] - 0s 76us/step - loss: 0.1746 - val_loss: 0.0937\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - 0s 90us/step - loss: 0.1620 - val_loss: 0.0740\n",
      "Epoch 8/10\n",
      "209/209 [==============================] - 0s 142us/step - loss: 0.1496 - val_loss: 0.0564\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - 0s 103us/step - loss: 0.1377 - val_loss: 0.0413\n",
      "Epoch 10/10\n",
      "209/209 [==============================] - 0s 96us/step - loss: 0.1289 - val_loss: 0.0288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:MAPE for 2018-02-28: 10.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 213 samples, validate on 12 samples\n",
      "Epoch 1/10\n",
      "213/213 [==============================] - 4s 21ms/step - loss: 0.2614 - val_loss: 0.2024\n",
      "Epoch 2/10\n",
      "213/213 [==============================] - 0s 75us/step - loss: 0.2365 - val_loss: 0.1739\n",
      "Epoch 3/10\n",
      "213/213 [==============================] - 0s 78us/step - loss: 0.2178 - val_loss: 0.1479\n",
      "Epoch 4/10\n",
      "213/213 [==============================] - 0s 87us/step - loss: 0.2007 - val_loss: 0.1237\n",
      "Epoch 5/10\n",
      "213/213 [==============================] - 0s 95us/step - loss: 0.1854 - val_loss: 0.1017\n",
      "Epoch 6/10\n",
      "213/213 [==============================] - 0s 88us/step - loss: 0.1713 - val_loss: 0.0810\n",
      "Epoch 7/10\n",
      "213/213 [==============================] - 0s 79us/step - loss: 0.1573 - val_loss: 0.0624\n",
      "Epoch 8/10\n",
      "213/213 [==============================] - 0s 94us/step - loss: 0.1443 - val_loss: 0.0461\n",
      "Epoch 9/10\n",
      "213/213 [==============================] - 0s 93us/step - loss: 0.1347 - val_loss: 0.0330\n",
      "Epoch 10/10\n",
      "213/213 [==============================] - 0s 91us/step - loss: 0.1235 - val_loss: 0.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:MAPE for 2018-03-31: 10.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 218 samples, validate on 12 samples\n",
      "Epoch 1/10\n",
      "218/218 [==============================] - 5s 23ms/step - loss: 0.2630 - val_loss: 0.1684\n",
      "Epoch 2/10\n",
      "218/218 [==============================] - 0s 76us/step - loss: 0.2379 - val_loss: 0.1424\n",
      "Epoch 3/10\n",
      "218/218 [==============================] - 0s 85us/step - loss: 0.2192 - val_loss: 0.1191\n",
      "Epoch 4/10\n",
      "218/218 [==============================] - 0s 70us/step - loss: 0.2033 - val_loss: 0.0978\n",
      "Epoch 5/10\n",
      "218/218 [==============================] - 0s 96us/step - loss: 0.1874 - val_loss: 0.0782\n",
      "Epoch 6/10\n",
      "218/218 [==============================] - 0s 94us/step - loss: 0.1728 - val_loss: 0.0608\n",
      "Epoch 7/10\n",
      "218/218 [==============================] - 0s 108us/step - loss: 0.1598 - val_loss: 0.0449\n",
      "Epoch 8/10\n",
      "218/218 [==============================] - 0s 93us/step - loss: 0.1487 - val_loss: 0.0317\n",
      "Epoch 9/10\n",
      "218/218 [==============================] - 0s 122us/step - loss: 0.1384 - val_loss: 0.0206\n",
      "Epoch 10/10\n",
      "218/218 [==============================] - 0s 98us/step - loss: 0.1277 - val_loss: 0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:MAPE for 2018-04-30: 16.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 222 samples, validate on 12 samples\n",
      "Epoch 1/10\n",
      "222/222 [==============================] - 5s 24ms/step - loss: 0.2591 - val_loss: 0.1636\n",
      "Epoch 2/10\n",
      "222/222 [==============================] - 0s 69us/step - loss: 0.2346 - val_loss: 0.1380\n",
      "Epoch 3/10\n",
      "222/222 [==============================] - 0s 64us/step - loss: 0.2170 - val_loss: 0.1158\n",
      "Epoch 4/10\n",
      "222/222 [==============================] - 0s 78us/step - loss: 0.1997 - val_loss: 0.0948\n",
      "Epoch 5/10\n",
      "222/222 [==============================] - 0s 88us/step - loss: 0.1848 - val_loss: 0.0755\n",
      "Epoch 6/10\n",
      "222/222 [==============================] - 0s 108us/step - loss: 0.1702 - val_loss: 0.0580\n",
      "Epoch 7/10\n",
      "222/222 [==============================] - 0s 71us/step - loss: 0.1561 - val_loss: 0.0424\n",
      "Epoch 8/10\n",
      "222/222 [==============================] - 0s 97us/step - loss: 0.1428 - val_loss: 0.0291\n",
      "Epoch 9/10\n",
      "222/222 [==============================] - 0s 82us/step - loss: 0.1321 - val_loss: 0.0183\n",
      "Epoch 10/10\n",
      "222/222 [==============================] - 0s 84us/step - loss: 0.1216 - val_loss: 0.0108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:MAPE for 2018-05-31: 18.07%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 226 samples, validate on 12 samples\n",
      "Epoch 1/10\n",
      "226/226 [==============================] - 6s 25ms/step - loss: 0.2627 - val_loss: 0.1970\n",
      "Epoch 2/10\n",
      "226/226 [==============================] - 0s 48us/step - loss: 0.2374 - val_loss: 0.1694\n",
      "Epoch 3/10\n",
      "226/226 [==============================] - 0s 56us/step - loss: 0.2184 - val_loss: 0.1445\n",
      "Epoch 4/10\n",
      "226/226 [==============================] - 0s 71us/step - loss: 0.2017 - val_loss: 0.1208\n",
      "Epoch 5/10\n",
      "226/226 [==============================] - 0s 75us/step - loss: 0.1845 - val_loss: 0.0987\n",
      "Epoch 6/10\n",
      "226/226 [==============================] - 0s 78us/step - loss: 0.1698 - val_loss: 0.0783\n",
      "Epoch 7/10\n",
      "226/226 [==============================] - 0s 79us/step - loss: 0.1558 - val_loss: 0.0598\n",
      "Epoch 8/10\n",
      "226/226 [==============================] - 0s 162us/step - loss: 0.1428 - val_loss: 0.0439\n",
      "Epoch 9/10\n",
      "226/226 [==============================] - 0s 124us/step - loss: 0.1322 - val_loss: 0.0305\n",
      "Epoch 10/10\n",
      "226/226 [==============================] - 0s 94us/step - loss: 0.1215 - val_loss: 0.0199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:MAPE for 2018-06-30: 29.28%\n"
     ]
    }
   ],
   "source": [
    " def get_next_monday(df, date):\n",
    "    first = True\n",
    "    while len(df[df.index == str(date).split()[0]]) == 0:\n",
    "        if first:\n",
    "            date += timedelta(days=((7 - date.weekday()) % 7))\n",
    "            first = False\n",
    "        else:\n",
    "            date += timedelta(7)\n",
    "    return date\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def test_sol(date):\n",
    "    df = pd.read_csv('./data/retrieved_data.csv')\n",
    "    ppp = PPPredictor()\n",
    "    prepared = ppp.prepare_data(df, date)\n",
    "    ppp.fit(prepared)\n",
    "    \n",
    "    df.index = pd.to_datetime(df['Date'])\n",
    "    df.drop(['Date'], axis=1, inplace=True)\n",
    "    for col in df.columns:\n",
    "        df[col].interpolate(method='time', inplace=True)\n",
    "    \n",
    "    start = pd.to_datetime(date) + timedelta(3 * 30)\n",
    "    end = pd.to_datetime(date) + timedelta(4 * 30)\n",
    "    pred = []\n",
    "    actual = []\n",
    "    for dt in pd.date_range(start, end, freq='W'):\n",
    "        pred.append(ppp.predict(str(dt).split()[0]))\n",
    "        actual_dt = get_next_monday(df, dt)\n",
    "        right_val = df[df.index == str(actual_dt).split()[0]]['PPSpotAvgPrice'].iloc[0]\n",
    "        actual.append(right_val)\n",
    "    logger.info('MAPE for {}: {:.2f}%'.format(date, mean_absolute_percentage_error(pred, actual)))\n",
    "\n",
    "for dt in pd.date_range(start=pd.to_datetime('2017-12-01'), \n",
    "                        end=pd.to_datetime('2018-07-01'), freq='M'):\n",
    "    test_sol(str(dt).split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
